{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "from time import sleep, time\n",
    "import toolz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ssievert/Developer/dask/distributed/distributed/__init__.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distributed\n",
    "distributed.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def get_model(model=None):\n",
    "    if model is None:\n",
    "        return Net()\n",
    "    return getattr(torchvision.models, model)()\n",
    "\n",
    "resnet_models = [m for m in dir(torchvision.models)\n",
    "                 if 'resnet' in m and m != 'resnet']\n",
    "models = [get_model(model=model) for model in resnet_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(batch_size=64, test_batch_size=1000,\n",
    "                       epochs=2, lr=0.01, momentum=0.5,\n",
    "                       no_cuda=True, seed=42, log_interval=80)\n",
    "    \n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:56886\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:56886' processes=8 cores=8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, wait\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "def clone(model):\n",
    "    return copy.deepcopy(model)\n",
    "\n",
    "class PS:\n",
    "    model = None\n",
    "    n_steps = 0\n",
    "\n",
    "    def __init__(self, model, args, device, max_iter=30):\n",
    "        model = model.to(device)\n",
    "        self.model = model\n",
    "        self._model = clone(model)\n",
    "        self.optimizer = optim.SGD(self._model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "        self.n_steps = 0\n",
    "        self._grads_recvd = 0\n",
    "        self._updating = False\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def pull(self):\n",
    "        \"\"\"\n",
    "        For a worker to pull a model from this PS\n",
    "        \"\"\"\n",
    "        return self.model\n",
    "\n",
    "    def push(self, grads, key=None):\n",
    "        \"\"\"\n",
    "        For a worker to push some gradients to this PS\n",
    "        \"\"\"\n",
    "        if grads:\n",
    "            if self.n_steps > self.max_iter:\n",
    "                return None\n",
    "            if key != self.n_steps or self._updating:\n",
    "                assert key < self.n_steps\n",
    "                return self.n_steps\n",
    "            \n",
    "            assert not self._updating\n",
    "            if self._grads_recvd == 0:\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            self._grads_recvd += 1\n",
    "            self.aggregate(grads)\n",
    "            if self._grads_recvd == 4:\n",
    "                self._updating = True\n",
    "                self._grads_recvd = 0\n",
    "                self.step()\n",
    "                self.n_steps += 1\n",
    "                self._updating = False\n",
    "        return self.n_steps\n",
    "\n",
    "    def aggregate(self, grads):\n",
    "        for name, param in self._model.named_parameters():\n",
    "            if param.grad is None:\n",
    "                param.grad = 0 * param\n",
    "            param.grad += grads[name]\n",
    "            \n",
    "    def step(self):\n",
    "        self.optimizer.step()\n",
    "        self.model = clone(self._model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 50\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_loader, model = client.scatter([train_loader, model])\n",
    "\n",
    "ps = client.submit(PS, model, args, device,\n",
    "                   actor=True, max_iter=30).result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, data, target):\n",
    "    model.train()\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toolz\n",
    "def worker(ps, device, train_loader):\n",
    "    last_step = -1\n",
    "    step = 0\n",
    "    train_loader = iter(train_loader)\n",
    "    start_step = ps.push(None).result()\n",
    "    while True:\n",
    "        if step != last_step:\n",
    "            model = ps.pull().result()\n",
    "            last_step = step\n",
    "        data, target = next(train_loader)\n",
    "        model = train(model, device, data, target)\n",
    "        \n",
    "        check = toolz.first(model.parameters())\n",
    "        check = check.detach().numpy().flat[:3]\n",
    "        print(step, check)\n",
    "        \n",
    "        grads = {name: p.grad.data for name, p in model.named_parameters()}\n",
    "        \n",
    "        step = ps.push(grads, key=step).result()\n",
    "        if step is None:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = [client.submit(worker, ps, device, train_loader)\n",
    "           for i in range(num_workers)]\n",
    "wait(futures);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ps.model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization time\n",
    "\n",
    "Wait time is a lot of serialization time, + 1-2ms each way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.46 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit model = ps.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.62 ms per loop\n"
     ]
    }
   ],
   "source": [
    "from distributed.protocol import serialize, deserialize\n",
    "%timeit _ = deserialize(*serialize(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/var/folders/kk/wvsqd9_j5j12y8bszfc6gr9h0000gp/T/tmpyi76hecc'. \n"
     ]
    }
   ],
   "source": [
    "%%snakeviz  \n",
    "for i in range(100):\n",
    "    deserialize(*serialize(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
