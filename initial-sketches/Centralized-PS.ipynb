{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a centralized parameter server with PyTorch's MNIST example. Is is centralized because the model is stored in one place. This requires the communication of models in addition to the communication of gradients.\n",
    "\n",
    "The next couple cells are basically copy/pasted from [PyTorch's MNIST example](https://github.com/pytorch/examples/tree/master/mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "./centralized.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('./centralized.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depends on serialization of torch.Device objects: https://github.com/pytorch/pytorch/pull/7713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(batch_size=64, test_batch_size=1000,\n",
    "                       epochs=2, lr=0.01, momentum=0.5,\n",
    "                       no_cuda=True, seed=42, log_interval=80)\n",
    "    \n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ssievert/Developer/dask/distributed/distributed/__init__.py\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:63842\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:63843/status' target='_blank'>http://127.0.0.1:63843/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:63842' processes=8 cores=8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distributed import Client\n",
    "import distributed as d\n",
    "print(d.__file__)\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell is *almost* copy and pasted. It takes in a `(data, target)` pair instead of `train_loader`, does not do anything with the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, data, target):\n",
    "    model.train()\n",
    "    \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    # optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    # optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import copy\n",
    "\n",
    "def clone(model):\n",
    "    return copy.deepcopy(model)\n",
    "\n",
    "def test_clone_no_modification():\n",
    "    model = Net()\n",
    "    m2 = clone(model)\n",
    "\n",
    "    m2_params = dict(m2.named_parameters())\n",
    "    for name, param in model.named_parameters():\n",
    "        param = param.detach()\n",
    "        param.data += 1\n",
    "        assert (m2_params[name].data != param.data).all()\n",
    "        \n",
    "test_clone_no_modification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the definition of our actor. It sends out models, and receives gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PS:\n",
    "    def __init__(self, model, num_workers=1):\n",
    "        self.models = {0: model}\n",
    "        self._grads = {}\n",
    "        self.model = model\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def pull(self, key):\n",
    "        \"\"\"\n",
    "        For a worker to pull a model from this PS\n",
    "        \"\"\"\n",
    "        if key not in self.models:\n",
    "            return None\n",
    "        return self.models[key]\n",
    "    \n",
    "    def pull_latest(self):\n",
    "        key = max(self.models)\n",
    "        return key, self.pull(key)\n",
    "        \n",
    "    def push(self, key, grads):\n",
    "        \"\"\"\n",
    "        For a worker to push some gradients to this PS\n",
    "        \"\"\"\n",
    "        if key not in self._grads:\n",
    "            self._grads[key] = []\n",
    "        self._grads[key] += [grads]\n",
    "        \n",
    "        # have we collected enough gradients?\n",
    "        if len(self._grads[key]) == self.num_workers:\n",
    "            old_model = clone(self.model)\n",
    "            self.aggregate(self._grads[key])\n",
    "            self.models[key + 1] = self.model\n",
    "            self.models[key] = old_model\n",
    "    \n",
    "    def aggregate(self, grads):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            worker_grads = [grad[name] for grad in grads]\n",
    "            param.grad = sum(worker_grads)\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from time import sleep, time\n",
    "import toolz\n",
    "import numpy as np\n",
    "\n",
    "def worker(ps, device, train_loader,\n",
    "           worker_id=0, num_workers=1,\n",
    "           iters=5):\n",
    "    meta = {'comm_model': 0, 'compute_grad': 0, 'comm_grad': 0}\n",
    "    step_start, _model = ps.pull_latest().result()\n",
    "    whole_start = time()\n",
    "    params = [np.prod(tuple(p.size())) for p in _model.parameters()]\n",
    "                        \n",
    "    for step in range(step_start, step_start + iters):\n",
    "        start = time()\n",
    "        while _model is None:\n",
    "            _model = ps.pull(key=step).result()\n",
    "            sleep(1e-4)\n",
    "        meta['comm_model'] += time() - start\n",
    "        model, _model = _model, None\n",
    "        \n",
    "        param_check = toolz.last(model.parameters())\n",
    "        check = param_check.detach().numpy().flat[:4]\n",
    "        print(\"worker {} iter {}, last params = {}\".format(worker_id, step, check))\n",
    "            \n",
    "        data, target = next(iter(train_loader))\n",
    "        start = time()\n",
    "        model = train(model, device, data, target)\n",
    "        grads = {name: p.grad.data for name, p in model.named_parameters()}\n",
    "        meta['compute_grad'] += time() - start\n",
    "        \n",
    "        start = time()\n",
    "        ps.push(step, grads)\n",
    "        meta['comm_grad'] += time() - start\n",
    "    meta = {k: v / iters for k, v in meta.items()}\n",
    "    meta['avg_step_time'] = (time() - whole_start) / iters\n",
    "    meta['params'] = sum(params)\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Actor: PS, key=PS-8dfe20cd-92e7-423f-8700-209322237489>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "num_workers = 4\n",
    "\n",
    "model = client.scatter(model)\n",
    "train_loader = client.scatter(train_loader)\n",
    "\n",
    "ps = client.gather(client.submit(PS, model, num_workers=num_workers,\n",
    "                                 actor=True))\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's calling the train function. This can be called repeated times, since the function `worker` gets the latest model to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = [client.submit(worker, ps, device, train_loader,\n",
    "                         worker_id=i, num_workers=num_workers)\n",
    "           for i in range(num_workers)]\n",
    "meta = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_step_time</th>\n",
       "      <th>comm_grad</th>\n",
       "      <th>comm_model</th>\n",
       "      <th>compute_grad</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.359408</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.281392</td>\n",
       "      <td>0.061811</td>\n",
       "      <td>21840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261331</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.165772</td>\n",
       "      <td>0.080132</td>\n",
       "      <td>21840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125976</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>0.077871</td>\n",
       "      <td>21840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.122465</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.045126</td>\n",
       "      <td>0.061952</td>\n",
       "      <td>21840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_step_time  comm_grad  comm_model  compute_grad  params\n",
       "0       0.359408   0.000143    0.281392      0.061811   21840\n",
       "1       0.261331   0.000202    0.165772      0.080132   21840\n",
       "2       0.125976   0.000139    0.033504      0.077871   21840\n",
       "3       0.122465   0.001177    0.045126      0.061952   21840"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(meta)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12f3857b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEfCAYAAACtRRYAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHYNJREFUeJzt3Xt0VfWZ//H3Q7hECisgZHW1ggZmqArJIQFCoOYnxFTBIjdFwQtGaaWWYltar8tCGRx/C61TRrygWPE2MsJAKSyl46VAlRYwoVAgUBA0SsZOfwjeCKQm4fn9cQ6nMeTASXKSE9if11osz977u/d+EuSTne/e5znm7oiISDC0SXYBIiLSchT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEAUeiLiASIQl9EJEDaJruAurp37+4ZGRnJLkNE5LSyefPmj9w9/VTjWl3oZ2RkUFJSkuwyREROK2b2fjzjNL0jIhIgCn0RkQBR6IuIBEirm9MXkZZXVVVFeXk5lZWVyS5FTiE1NZUePXrQrl27Ru2v0BcRysvL6dy5MxkZGZhZssuRGNydgwcPUl5eTq9evRp1DE3viAiVlZV069ZNgd/KmRndunVr0m9kCn0RAVDgnyaa+vek0BcRCRDN6Z/hMu5+JdklxKVs7qhklyC1JPr/G/39th660heRwFm3bh1//OMfE3rMsrIyFi9eHF0uKSnhhz/8YULPkQgKfREJnJYI/UGDBjF//vyEniMRFPoi0iqMGzeOgQMH0q9fPxYuXMiCBQu48847o9ufffZZbrvtNgDuu+8+LrjgAi699FKuvfZaHnrooZjHnT9/Pn379iUUCjFp0iTKysp44oknmDdvHtnZ2bz11lscOHCAq666itzcXHJzc/nDH/4AwOzZs5k8eTKXXHIJffr04amnnop5nrvvvpu33nqL7Oxs5s2bx7p167jiiiuixykqKuKyyy4jIyODX//619x5551kZWUxcuRIqqqqANi8eTPDhg1j4MCBjBgxgr/+9a9N/r7WpTl9EWkVFi1axNlnn83Ro0fJzc3ld7/7HRdddBEPPvggAEuWLOHee++lpKSE5cuXs2XLFqqrqxkwYAADBw6Medy5c+fy3nvv0aFDBz755BO6dOnCrbfeSqdOnbj99tsBuO6665gxYwb5+fl88MEHjBgxgl27dgGwbds2Nm7cSEVFBTk5OYwaNYqvf/3r9Z7noYce4uWXXwbCv03Utm/fPtauXcvOnTsZOnQoy5cv58EHH2T8+PG88sorjBo1ittuu42VK1eSnp4e/XoXLVqUiG9vlEJfRFqF+fPns2LFCgD279/Pe++9R+/evdm4cSN9+vRh9+7dXHTRRTz88MOMHTuWs846C4DRo0ef9LihUIjrr7+ecePGMW7cuHrHvPHGG+zcuTO6/Nlnn/H5558DRM911llnUVBQwNtvvx3zOCdz+eWX065dO7KysqipqWHkyJEAZGVlUVZWxu7du9mxYweXXnopADU1NXzta19r8HlORaEvIkm3bt063njjDTZs2EDHjh0ZPnw4lZWVTJw4kaVLl3LBBRcwfvx4zAx3b9CxX3nlFd58801WrVrFfffdR2lp6Qljjh07xoYNG6I/SGqr+1x8Y5+T79ChAwBt2rShXbt20eO0adOG6upq3J1+/fqxYcOGRh0/Xgp9ETlBSz9i+emnn9K1a1c6duzIX/7yFzZu3AjAlVdeyf333895553HAw88AEB+fj7f+973uOeee6iuruaVV17hlltuqfe4x44dY//+/RQUFJCfn8/ixYs5fPgwnTt35rPPPouOu+yyy3j00Ue54447ANi6dSvZ2dkArFy5knvuuYeKigrWrVvH3Llz6z1X586do78dNMb555/PgQMH2LBhA0OHDqWqqoo9e/bQr1+/Rh+zPrqRKyJJN3LkSKqrqwmFQsycOZMhQ4YA0LVrV/r27cv777/P4MGDAcjNzWXMmDH079+fK6+8kkGDBpGWllbvcWtqarjhhhvIysoiJyeHGTNm0KVLF0aPHs2KFSuiN3Lnz59PSUkJoVCIvn378sQTT0SPMXjwYEaNGsWQIUOYOXNmvfP5EJ5Gatu2Lf3792fevHkN/h60b9+eZcuWcdddd9G/f3+ys7MT/oQRgDX0V6XmNmjQINcnZyWO3pwl8di1axcXXnhhssuI2+HDh+nUqRNHjhzh4osvZuHChQwYMCDh55k9e/aXbvi2FvX9fZnZZncfdKp9Nb0jIqedqVOnsnPnTiorKykqKmqWwD9TKfRF5LRT+01Qx/3gBz+IPl9/3I9+9CNuvvnmRp9n9uzZJ6zbvn07kydP/tK6Dh06sGnTpkafpyUp9EXkjPDYY4+1yHmysrLYunVri5yrOehGrohIgMQV+mY20sx2m9leM7u7nu0/MbOdZrbNzH5nZufV2lZkZu9E/hQlsngREWmYU4a+maUAjwGXA32Ba82sb51hW4BB7h4ClgEPRvY9G/g5kAcMBn5uZl0TV76IiDREPHP6g4G97v4ugJm9BIwFou9Zdve1tcZvBG6IvB4BvO7uhyL7vg6MBP6z6aWLSLOZXf9z740/3qeJPZ40WjzTO+cA+2stl0fWxfId4LcN2dfMpppZiZmVHDhwII6SREROD2VlZWRmZia7jKh4Qr++RhP1vqPLzG4ABgG/aMi+7r7Q3Qe5+6D09PQ4ShIRSa6amppkl9Ao8YR+OdCz1nIP4MO6g8zsW8C9wBh3/3tD9hURef755wmFQvTv35/Jkyfz/vvvU1hYSCgUorCwkA8++ACAm266ie9///sUFBTQu3dvfv/73zNlyhQuvPBCbrrppujxOnXqxF133cXAgQP51re+xdtvv83w4cPp3bs3q1atilnHkSNHuOaaawiFQkycOJG8vDyOdwno1KkTs2bNIi8vjw0bNjBnzhxyc3PJzMxk6tSp0WZwmzdvpn///gwdOrTFHiWNVzyhXwz0MbNeZtYemAR86TtmZjnAk4QD///V2vQqcJmZdY3cwL0ssk5EJKq0tJT777+fNWvW8Oc//5mHH36Y6dOnc+ONN7Jt2zauv/76L3304Mcff8yaNWuYN28eo0ePZsaMGZSWlrJ9+/boM/QVFRUMHz6czZs307lzZ372s5/x+uuvs2LFCmbNmhWzlscff5yuXbuybds2Zs6cyebNm6PbKioqyMzMZNOmTeTn5zN9+nSKi4vZsWMHR48ejfbSv/nmm5k/f36zd8xsjFOGvrtXA9MJh/UuYKm7l5rZHDMbExn2C6AT8F9mttXMVkX2PQTcR/gHRzEw5/hNXRGR49asWcOECRPo3r07AGeffTYbNmzguuuuA2Dy5MmsX78+On706NGYGVlZWXz1q18lKyuLNm3a0K9fP8rKyoBwA7PaPeuHDRsW7Wd/fEx91q9fz6RJkwDIzMwkFApFt6WkpHDVVVdFl9euXUteXh5ZWVmsWbOG0tJSPv30Uz755BOGDRsWrb01iesdue6+GlhdZ92sWq+/dZJ9FwGJ/egXETmjuPsp+9TX3l67N/3x18eXq6urAU7oWV97n+NjYtUSS2pqKikpKQBUVlYybdo0SkpK6NmzJ7Nnz6aysjKuryWZ1IZBRE7Uwo9YFhYWMn78eGbMmEG3bt04dOgQ3/zmN3nppZeYPHkyL774Ivn5+S1SS35+PkuXLqWgoICdO3eyffv2esdVVlYC0L17dw4fPsyyZcuYMGECXbp0IS0tjfXr15Ofn8+LL77YInXHS6EvIknXr18/7r33XoYNG0ZKSgo5OTnMnz+fKVOm8Itf/IL09HSeeeaZFqll2rRpFBUVEQqFyMnJIRQK1duvv0uXLtxyyy1kZWWRkZFBbm5udNszzzzDlClT6NixIyNGjGiRuuOlfvpnOPXTl3icbv30m1NNTQ1VVVWkpqayb98+CgsL2bNnD+3bt092aVHqpy8ikiBHjhyhoKCAqqoq3J0FCxa0qsBvKoW+iATSq6++yl133fWldb169WLFihWcybMNCn0RCaQRI0a0uvn2lqB++iIiAaLQFxEJEIW+iEiAaE5fRE6Q9VxWQo+3vaj+Nzid6crKyrjiiivYsWNHk8Ykkq70RUQCRKEvIq1Ca2mt/OyzzzJu3DhGjx5Nr169ePTRR/nlL39JTk4OQ4YM4dChcM/IrVu3MmTIEEKhEOPHj+fjjz8GYrdVrqmp4Y477iA3N5dQKMSTTz7ZDN/FU1Poi0jStabWygA7duxg8eLFvP3229x777107NiRLVu2MHToUJ5//nkAbrzxRh544AG2bdtGVlYW//Iv/wLEbqv89NNPk5aWRnFxMcXFxTz11FO89957ifw2xkWhLyJJ15paKwMUFBTQuXNn0tPTSUtLY/To0dHjlJWVndA+uaioiDfffPOkbZVfe+01nn/+ebKzs8nLy+PgwYO88847Tf/mNZBu5IpI0rWm1sq1j9/QfU/2dbg7jzzyyAlvCDvVD6BE05W+iCRdYWEhS5cu5eDBgwBfaq0MtGhr5XikpaXRtWtX3nrrLQBeeOEFhg0b9qW2ysCX2iqPGDGCBQsWUFVVBcCePXuoqKho8dp1pS8iJ2jpRyxbU2vleD333HPceuutHDlyhN69e0fri9VW+bvf/S5lZWUMGDAAdyc9PZ3f/OY3LV63Wiuf4dRaWeKh1sqnl6a0Vtb0johIgGh6R0QC6WStlc9kCn0RCSS1VhYRkTOeQl9EJEAU+iIiAaLQFxEJEN3IFZET7Logsc/sX/iXXQk9XnPYunUrH374Id/+9reTXUqz9tjXlb6ICOHQX716dbOeo6amplmPHw+Fvoi0Cs3RT/+nP/0pAwYMoLCwkAMHDgAwfPhwjr/r/6OPPiIjI4MvvviCWbNmsWTJErKzs1myZAkVFRVMmTKF3NxccnJyWLlyZczajxw5wjXXXEMoFGLixInk5eVFz9GpUydmzZpFXl4eGzZsYM6cOeTm5pKZmcnUqVM53hUhVh/+RFPoi0jSNVc//QEDBvCnP/2JYcOGRfvd16d9+/bMmTOHiRMnsnXrViZOnMj999/PJZdcQnFxMWvXruWOO+6I2SDt8ccfp2vXrmzbto2ZM2eyefPm6LaKigoyMzPZtGkT+fn5TJ8+neLiYnbs2MHRo0d5+eWXgdh9+BNNoS8iSdcc/fTbtGnDxIkTAbjhhhu+tH88XnvtNebOnUt2djbDhw+nsrIy+ttGXevXr2fSpEkAZGZmEgqFottSUlK46qqrostr164lLy+PrKws1qxZQ2lp6Un78CeabuSKSNI1Rz/9WPu3bduWY8eOAVBZWXnSmpYvX875558fV/2xpKamkpKSEj3ftGnTKCkpoWfPnsyePZvKysq4vv5E0ZW+iCRdc/TTP3bsGMuWLQNg8eLF0f0zMjKi0y/HtwN07tyZzz//PLo8YsQIHnnkkWigb9myJea58vPzWbp0KQA7d+5k+/b6W1Mf/yHTvXt3Dh8+HD3/yfrwJ5qu9EXkBC39iGVz9NP/yle+QmlpKQMHDiQtLY0lS5YAcPvtt3PNNdfwwgsvcMkll0THFxQURKdz7rnnHmbOnMmPf/xjQqEQ7k5GRkZ0/r2uadOmUVRURCgUIicnh1AoRFpa2gnjunTpwi233EJWVhYZGRnk5uZGt8Xqw59o6qd/hlM/fYnHmdhPv1OnThw+fLhFzlVTU0NVVRWpqans27ePwsJC9uzZQ/v27ZvlfE3pp68rfRGRJjpy5AgFBQVUVVXh7ixYsKDZAr+pFPoickZqjqv8k/XgP11mKBT6IgLE9wRN0LWGHvxNnZLX0zsiQmpqKgcPHmxyoEjzcncOHjxIampqo48R15W+mY0EHgZSgF+5+9w62y8G/h0IAZPcfVmtbTXA8eeXPnD3MY2uVkSaRY8ePSgvL4+2KpDWKzU1lR49ejR6/1OGvpmlAI8BlwLlQLGZrXL3nbWGfQDcBNxezyGOunt2oysUkWbXrl07evXqlewypAXEc6U/GNjr7u8CmNlLwFggGvruXhbZdqwZahQRkQSJZ07/HGB/reXyyLp4pZpZiZltNLNx9Q0ws6mRMSX69VJEpPnEE/r13c5vyN2ecyNvGLgO+Hcz+6cTDua+0N0Hufug9PT0BhxaREQaIp7QLwd61lruAXwY7wnc/cPIf98F1gE5DahPREQSKJ7QLwb6mFkvM2sPTAJWxXNwM+tqZh0ir7sDF1HrXoCIiLSsU4a+u1cD04FXgV3AUncvNbM5ZjYGwMxyzawcuBp40sxKI7tfCJSY2Z+BtcDcOk/9iIhIC4rrOX13Xw2srrNuVq3XxYSnferu90cgq4k1iohIgugduSIiAaLQFxEJEIW+iEiAKPRFRAJEoS8iEiAKfRGRAFHoi4gEiEJfRCRAFPoiIgGi0BcRCRCFvohIgCj0RUQCJK6GayISlvXc6dE/cHvR9mSXIK2UrvRFRAJEoS8iEiAKfRGRAFHoi4gEiEJfRCRAFPoiIgGi0BcRCRCFvohIgCj0RUQCRKEvIhIgCn0RkQBR6IuIBIhCX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEAUeiLiASIQl9EJEAU+iIiAaLQFxEJEIW+iEiAKPRFRAJEoS8iEiBxhb6ZjTSz3Wa218zurmf7xWb2JzOrNrMJdbYVmdk7kT9FiSpcREQa7pShb2YpwGPA5UBf4Foz61tn2AfATcDiOvueDfwcyAMGAz83s65NL1tERBojniv9wcBed3/X3b8AXgLG1h7g7mXuvg04VmffEcDr7n7I3T8GXgdGJqBuERFphHhC/xxgf63l8si6eMS1r5lNNbMSMys5cOBAnIcWEZGGiif0rZ51Hufx49rX3Re6+yB3H5Senh7noUVEpKHiCf1yoGet5R7Ah3Eevyn7iohIgsUT+sVAHzPrZWbtgUnAqjiP/ypwmZl1jdzAvSyyTkREkuCUoe/u1cB0wmG9C1jq7qVmNsfMxgCYWa6ZlQNXA0+aWWlk30PAfYR/cBQDcyLrREQkCdrGM8jdVwOr66ybVet1MeGpm/r2XQQsakKNIiKSIHpHrohIgCj0RUQCRKEvIhIgCn0RkQBR6IuIBIhCX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEAUeiLiASIQl9EJEAU+iIiAaLQFxEJEIW+iEiAKPRFRAJEoS8iEiAKfRGRAFHoi4gEiEJfRCRA2ia7ABFJvF0XXJjsEuJy4V92JbuEwNGVvohIgCj0RUQCRKEvIhIgCn0RkQBR6IuIBIhCX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEAUeiLiASIQl9EJEAU+iIiARJX6JvZSDPbbWZ7zezuerZ3MLMlke2bzCwjsj7DzI6a2dbInycSW76IiDTEKT9ExcxSgMeAS4FyoNjMVrn7zlrDvgN87O7/bGaTgAeAiZFt+9w9O8F1i4hII8RzpT8Y2Ovu77r7F8BLwNg6Y8YCz0VeLwMKzcwSV6aIiCRCPKF/DrC/1nJ5ZF29Y9y9GvgU6BbZ1svMtpjZ783s/zSxXhERaYJ4PiO3vit2j3PMX4Fz3f2gmQ0EfmNm/dz9sy/tbDYVmApw7rnnxlGSiIg0RjxX+uVAz1rLPYAPY40xs7ZAGnDI3f/u7gcB3H0zsA/4Rt0TuPtCdx/k7oPS09Mb/lWIiEhc4gn9YqCPmfUys/bAJGBVnTGrgKLI6wnAGnd3M0uP3AjGzHoDfYB3E1O6iIg01Cmnd9y92symA68CKcAidy81szlAibuvAp4GXjCzvcAhwj8YAC4G5phZNVAD3Oruh5rjCxERkVOLZ04fd18NrK6zblat15XA1fXstxxY3sQaRUQkQfSOXBGRAFHoi4gEiEJfRCRAFPoiIgGi0BcRCRCFvohIgCj0RUQCRKEvIhIgCn0RkQBR6IuIBIhCX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEAUeiLiASIQl9EJEAU+iIiAaLQFxEJEIW+iEiAKPRFRAJEoS8iEiAKfRGRAFHoi4gEiEJfRCRAFPoiIgGi0BcRCRCFvohIgCj0RUQCRKEvIhIgCn0RkQBR6IuIBIhCX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAiSu0DezkWa228z2mtnd9WzvYGZLIts3mVlGrW33RNbvNrMRiStdREQa6pShb2YpwGPA5UBf4Foz61tn2HeAj939n4F5wAORffsCk4B+wEjg8cjxREQkCeK50h8M7HX3d939C+AlYGydMWOB5yKvlwGFZmaR9S+5+9/d/T1gb+R4IiKSBG3jGHMOsL/WcjmQF2uMu1eb2adAt8j6jXX2PafuCcxsKjA1snjYzHbHVb2cMeyBZFcQt+7AR8ku4lTq/ireapklu4IzyXnxDIon9Ov7W/E4x8SzL+6+EFgYRy0iSWVmJe4+KNl1iDRWPNM75UDPWss9gA9jjTGztkAacCjOfUVEpIXEE/rFQB8z62Vm7QnfmF1VZ8wqoCjyegKwxt09sn5S5OmeXkAf4O3ElC4iIg11yumdyBz9dOBVIAVY5O6lZjYHKHH3VcDTwAtmtpfwFf6kyL6lZrYU2AlUAz9w95pm+lpEWoKmIeW0ZuELchERCQK9I1dEJEAU+iIiAaLQFxEJEIW+iEiAKPRFRAIknnfkigRS5I2G3wHGA18n/G7yD4GVwNPuXpXE8kQaRY9sisRgZv8JfEK4mWB5ZHUPwm9EPNvdJyarNpHGUuiLxGBmu939/Bjb9rj7N1q6JpGm0py+SGwfm9nVZhb9d2JmbcxsIvBxEusSaTSFvkhskwj3kvqbme0xsz3A34ArI9tETjua3hGJg5l1I/zvpdX30hc5GV3pi8TB3Q+6+0dm9nyyaxFpCj2yKRKDmdVtIW5AgZl1AXD3MS1flUjTKPRFYutBuC34r/jHJ8ENAv4tmUWJNIXm9EViiDy18yPg28Ad7r7VzN51995JLk2k0RT6IqdgZj2AeYSf3Bnj7ucmuSSRRtP0jsgpuHs5cLWZjQI+S3Y9Ik2hp3dETsLMzj1+4xYoBf5kZpnJrEmkKRT6IjGY2d3A74GNZvZd4L+By4ElZvaTpBYn0kia0xeJwcxKCT+t0xEoA3q7+wEz+wqwyd11xS+nHc3pi8RW4+5HzewL4ChwEMDdK8wsuZWJNJKu9EViMLNngfbAV4AjQDXhKZ5LgM7ufk3yqhNpHIW+SAyRD1G5mvAbs5YBg4HrgA+Ax9y9IonliTSKQl9EJED09I5II5jZb5Ndg0hj6EauSAxmNiDWJiC7JWsRSRSFvkhsxYSf06/vUZ0u9awTafUU+iKx7QK+5+7v1N1gZvuTUI9Ik2lOXyS22cT+N3JbC9YhkjAKfZEY3H0ZYGZWaGad6myuTEZNIk2l0BeJwcx+CKwkfFW/w8zG1tr8f5NTlUjTaE5fJLZbgIHuftjMMoBlZpbh7g9T/81dkVZPoS8SW4q7HwZw9zIzG044+M9DoS+nKU3viMT2v2YWfR4/8gPgCqA7kJW0qkSaQG0YRGKIfExitbv/bz3bLnL3PyShLJEmUeiLiASIpndERAJEoS8iEiAKfRGRAFHoi5xC5MNURM4IupErgRB5c9V/A5uAHGAPcCNwOzAaOAv4I+EGa25m6yLLFwGrIuN/RvjjEw8C17v738xsNtAL+BrwDeAnwBDgcuB/gNHuXmVmc4ExhD9y8TV3v73Zv2iReuhKX4LkfGChu4eAz4BpwKPunuvumYSD/4pa47u4+zB3/zdgPTDE3XOAl4A7a437J2AUMBb4D2Ctu2cR/jD1UWZ2NjAe6Bc5978261cpchIKfQmS/bWerf8PIB8oMLNNZrad8Aee96s1fkmt1z2AVyPj7qgz7rfuXgVsB1II/0ZBZDmD8A+YSuBXZnYl4Q9ZF0kKhb4ESd25TAceByZErsyfAlJrba/9weePEP6tIAv4Xp1xfwdw92NAlf9jzvQY0Nbdqwl/qPpyYBz/+KEg0uIU+hIk55rZ0MjrawlP2QB8FGmdPOEk+6YRnqMHKGrISSPHTnP31cCP0UctShLpqQQJkl1AkZk9CbwDLAC6Ep6GKSP88YixzAb+y8z+B9hI+OZtvDoDK80slXCjthkNrlwkQfT0jgRC5OmdlyM3bEUCS9M7IiIBoit9EZEA0ZW+iEiAKPRFRAJEoS8iEiAKfRGRAFHoi4gEyP8H5DEFr0kVcrUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show = df.groupby('params').mean()\n",
    "show.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
